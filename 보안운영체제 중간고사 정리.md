# 보안운영체제 중간고사 정리



## 1장 01프로세스

### 사용자 가시 레지스터 

- 사용자가 운영체제와 사용자 프로그램을 이용해 **정보 변경 가능**



### 사용자 가시 레지스터 종류

- 데이터 레지스터 (DR, Data Register) 
  - 함수 연산에 필요한 데이터를 저장한다. 값,문자 등을 저장하므로 산술 연산이나 논리 연산에 사용하며, 연산 결과로 플래그 값을 저장한다.
- 주소 레지스터 (AR,Address Register) 
  - 주소나 유효 주소를 계산하는 데 필요한 주소의 일부분을 저장한다. 주소 레지스터에 저장한 값(값 데이터)을 사용하여 산술 연산을 할 수 있다.
    - 기준 주소 레지스터 : 프로그램을 실행할 때 사용하는 기준 주소 값을 저장한다. 기준 주소는 하나의 프로그램이나 일부처럼 서로 관련 있는 정보를 저장하며, 연속된 저장 공간을 지정하는 데 참조할 수 있는 주소이다. 따라서 기준 주소 레지스터는 페이지나 세그먼트처럼 블록화된 정보에 접근하는데 사용한다.
    - 인덱스 레지스터 : 유효 주소를 계산하는 데 사용하는 주소 정보를 저장한다.
    - 스택 포인터 레지스터 : 메모리에 프로세서 스택을 구현하는 데 사용한다. 많은 프로세서와 주소 레지스터를 데이터 스택 포인터와 큐 포인터로 사용한다. 보통 반환 주소, 프로세서 상태 정보, 서브루틴의 임시 변수를 저장한다.



### 사용자 불가시 레지스터 

- 사용자가 **정보를 변경할 수 없는 레지스터**이다. 프로세서의 상태와 제어를 관리

### 사용자 불가시 레지스터 종류

- 프로그램 카운터 (PC,Program Counter) 
  - 다음에 실행할 명령어의 주소를 보관하는 레지스터이다.  계수기로 되어 있어 실행할 명령어를 메모리에서 읽으면 명령어의 길이만큼 증가하여 다음 명령어를 가르키며, 명령어는 목적 주소로 갱신 가능.
- 명령어 레지스터 (IR,Instruction Register) 
  - 현재 실행하는 명령어를 보관하는 레지스터이다.
- 누산기 (ACC,ACCumulator) 
  - 데이터를 일시적으로 저장하는 레지스터이다.
- 메모리 주소 레지스터 (MAR,Memory Address Register) 
  -  프로세서가 참조하려는 데이터의 주소를 명시하여 메모리에 접근하는 버퍼 레지스터 이다.
- 메모리 버퍼 레지스터 (MBR,Memory Buffer Regisrer) 
  -  프로세서가 메모리에서 읽거나 메모리에 저장할 데이터 자체를 보관하는 버퍼 레지스터이다.  메모리 데이터 레지스터  (MDR,Memory Data Register)라고도 한다.



### 메모리 계층 구조 

- 1950~1960년대 너무 비싼 메인 메모리의 가격 문제 떄문에 제안한 방법으로 메모리를 계층적으로 구성하여 **비용,속도,용량,접근시간 등을 상호 보완**

### 메모리 계층 종류

- 레지스터 : 프로세서가 사용한 데이터를 보관하는 가장 빠른 메모리
- 캐시 : 프로세서의 속도 차이를 보완하는 메모리
- 메인 메모리 : 프로세서 외부에  있으면서 프로세서에서 수행할 프로그램과 데이터를 저장하거나 프로세서에서 처리한 결과를 저장한다 주기억장치 or 1차 기억장치라고 한다. DRAM을 많이 이용
- 보조기억장치

> 레지스터,캐시,메인 메모리는 프로세서가 프로그램과 데이터에 직접 접근할 수 있다.
>
> 보조기억장치는 프로그램과 데이터를 메인 메모리에 옮겨야 실행 할 수 있다.



### 캐시

- 프로세서 내부나 외부에 있으며, 처리 속도가 빠른 프로세서와 상대적으로 느린 메인 메모리의 속도 차이를 보완하는 고속 버퍼

  - 메인 메모리에서 **데이터를 블록 단위** 로 가져와 프로세서에 **워드 단위** 로 전달하여 속도를 높임

  > 메인 메모리와 크기가 동일한 블록 여려 개로 구성되는데, 보통 8~64바이트 정도 크기의 블록으로 구성

  - 데이터가 이동하는 통로(대역폭)를 확대하여 프로세서와 메인 메모리의 속도 차이를 줄임

![주석 2019-10-12 143129](https://user-images.githubusercontent.com/37978105/66697499-1ee40e00-ed11-11e9-9d0b-f42d107eb73c.png)



- 캐시의 성는은 작은 용량의 캐시에 프로세서가 이후 참조할 정보가 얼마나 들어 있느냐로 좌우됨
  - 캐시 적중(캐시 히트) : 프로세서가 참조하려는 정보가 있을 때
  - 캐시 실패(캐시 미스) : 프로세서가 참조하려는 정보가 없을 때
- 블록의 크기는 캐시의 성능으로 좌우되는데, 실제 프로그램을 실행할 때 참조한 메모리에 대한 공간적 지역성과 시간적 지역성이 있기 때문
  - 공간적 지역성 : 대부분의 프로그램이 참조한 주소와 인접한 주소의 내용을 다시 참조하려는 특성
  - 시간적 지역성 : 한 번 참조한 주소를 곧 다시  참조하려는 특성
- 공간적 지역성과 시간적 지역성의 발생 원인
  - 프로그램이 명령어를 순차적으로 실행하려는 경향이 있어 명령어가 특정 지역 메모리에 인접해 있다.
  - 순환(단일 순환,  중첩 순환) 때문에 프로그램을 반복하더라도 메모리 일부 영역만 참조한다.
  - 대부분의 컴파일러를 메모리에 인접한 블록에 배열로 저장한다. 따라서 프로그램이 배열 원소에 순차적으로 자주 접근하므로 지역적인 배열 접근 경향이 있다.

> 지역성은 블록티 크면 캐시의 히트율이 올라갈 수 있음을 의미하지만,  블록이 커지면 이에 따른 전송 부담과 캐시 데이터 교체 작업이 자주 일어나므로 블록 크기를 무작정 늘릴 수는 없음.

```c
//공간적 지역성
main(){
    
}
//시간적 지역성
for (i=0;i<=n;i++){
    for(j=0;j<m;j++){
        x=x+(a[i][j]); // A
        or
        x=x+(a[j][i]); // B
    }
}
```



## 1장 02컴퓨터 시스템의 동작

### 명령어의 기본 구조

| 명령부   | 주소부    | 주소부    | 주소부 | 주소부 | 주소부     |
| :------- | --------- | --------- | ------ | ------ | ---------- |
| 연산부호 | 피연산자1 | 피연산자2 | ----   | ------ | 피연산자 n |

- **연산 부호 (OPcode)**
  - 프로세서가 실행할 동작인 연산 지정
  - 산술 연산, 논리 연산, 시프트, 보수 등 연산 정의
  - 연산 부호가 n비트이면 최대 2^n개 연산이 가능
- **피연산자(OPerand)**
  - 연산할 데이터 정보 저장
  - 데이터는 레지스터나 메모리, 가상 기억장치, 입출력장치 등에 위치할 수 있는데 보통 데이터 자체보다는 데이터의 위치 저장

![주석 2019-10-12 145332](https://user-images.githubusercontent.com/37978105/66697514-420ebd80-ed11-11e9-8eaa-6f8d297c9c12.png)



### 직접 주소와 간접 주소

- 피연산자의 위치를 명시하는 방법(직접 주소 또는 간접 주소)을 나타내는 모드 비트(mode bit) I를 추가하거나, 다음 명령어의 위치를 나타내는 주소를 추가 가능

- **직접 주소(direct address)**

  - 피연산자에 데이터가 있는 레지스터나 메모리 주소 지정

- **간접 주소(indirect address)**

  - 레지스터나 메모리 주소 정보 지정

  ![주석 2019-10-12 145745](https://user-images.githubusercontent.com/37978105/66697521-4dfa7f80-ed11-11e9-82b2-5b6abe8ffbce.png)





### 명령어의 실행 사이클

![주석 2019-10-12 150028](https://user-images.githubusercontent.com/37978105/66697529-5bb00500-ed11-11e9-9f6e-b87a34d91318.png)

### 인출 사이클(fetch cycle)

- 메모리에서 명령어를 읽어 명령어 레지스터에 저장하고, 다음 명령어를 실행하려고 프로그램 카운터를 증가시킴
- 인출 사이클에 소요되는 시간을 명령어 인출 시간이라고 함

### 실행 사이클(execution cycle)

- 인출한 명령어를 해독하고 그 결과에 따라 제어 신호를 발생시켜 명령어 실행
- 실행 사이클에서 소비되는 시간을 실행 시간이라고 함

### 간접 사이클(indirect cycle)

- 간접 주소 지정 방법을 사용하는 실행 사이클은 명령어를 수행하기 전에 실제 데이터가 저장된 주 기억장치의 주소인 유효 주소를 한 번 더 읽어 옴

### 인터럽트 사이클(interrupt cycle)

- 인터럽트 : 프로세서가 프로그램을 수행하는 동안 컴퓨터 시스템의 내부나 외부에서 발생하는 예기치 못한 사건
- 프로세서는 **실행 사이클을 완료한 후 인터럽트 요구가 있는지 검사.**인터럽트 요구가 없으면 다음 명령어를 인출하고, 인터럽트 요구가 있으면 현재 수행 중인 프로그램의 주소(프로그램 카운터) 값을 스택이나 메모리의 0번지와 같은 특정 장소에 저장. 프로그램 카운터에는 인터럽트 처리 루틴의 시작 주소를 저장해 두었다가 인터럽트 처리를 완료하면 중단된 프로그램으로 복귀하여 계속 수행

![주석 2019-10-12 153009](https://user-images.githubusercontent.com/37978105/66697535-68345d80-ed11-11e9-8745-9522b7effd86.png)

![주석 2019-10-12 153027](https://user-images.githubusercontent.com/37978105/66697542-75514c80-ed11-11e9-8e7d-ebcda6343134.png)

![주석 2019-10-12 153134](https://user-images.githubusercontent.com/37978105/66697545-80a47800-ed11-11e9-877d-02b6654b6236.png)



## 2장 01운영체제의 발전 과정과 유형

### 일괄 처리 시스템

- 1950년대에 계발된 초기 운영체제
  - 작업을 올리는 시간과 해제하는 시간 줄이는 데 관심(일괄 처리, 버퍼링, 스풀링 등 방법 도임)
- 일괄 처리
  - 일괄 처리는 직렬 처리 기술과 동일
  - 작업 준비 시간을 줄이려고 데이터가 발생할 때마다 즉시 처리하지 않고 데이터를 일정 기간 또는 일정량이 될 때까지 모아 두었다가 한꺼번에 처리
- 일괄 처리 장점
  - 많은 사용자와 프로그램이 컴퓨터 자원 공유
  - 컴퓨터 자원을 덜 사용 중일 때는 작업 처리 시간 교대 가능
  - 시시각각 수동으로 개입, 감독하여 컴퓨터 자원의 유휴 회피 가능

![주석 2019-10-12 154237](https://user-images.githubusercontent.com/37978105/66697553-8d28d080-ed11-11e9-9d0d-124d13bd47b2.png)

- 일괄 처리 단점
  - 준비 작업들의 유형이 동일해야 하고, 작업에 모든 유형의 입력 불가능
  - 입출력장치가 프로세서보다 **속도 느려** 프로세서의 유휴 상태 발생
  - 작업 우선순위 부여 관란.
  - 문제점 보완 위해 모니터링, 버퍼링, 스풀링 등 여러 방법 등장
- 버퍼링(buffering)
  - 유휴 시간이 없도록 입출력장치별로 입출력 버퍼 두어, 프로세서에서 연산 할 떄 동시에 다른 작업 입출력하는 아주 간단한 방법
- 스풀링(spooling)
  - 속도가 빠른 디스크를 버퍼처럼 사용 입출력장치에서 미리 읽는 것
  - 버퍼링이 컴퓨터 하드웨어의 일부인 버퍼를 사용 한다면, 스풀링은 별개의 오프라인 장치 사용
  - 버퍼링이 하나의 입출력 작업과 그 작업의 계산만 함께 할 수 있는 반면, 스풀링은 여러 작업의 입출력과 계산을 함께 할 수 있음
  - 프로세서에 일정한 디스크 공간, 테이블만 있으면 하나의 계산 작업과 다른 입출력 작업 중복 처리
  - 프로세서와 입출력장치가 고효율로 작업하게 함
  - 성능에 직접적으로 도움

### 다중 프로그래밍 시스템

- 프로세스가 다른 작업 수행 시 입출력 작업 불가능하여 프로세서와 메인 메모리의 활용도 떨어지는 일괄 처리 시스템의 큰 문제를 다중 프로그래밍 도입하여 해결
- 프로세서가 유휴 상태일 때 실행 중인 둘 이상의 작업이 프로세서를 전환 (인터리빙)하여 사용할 수 있도록 동작

![주석 2019-10-12 160429](https://user-images.githubusercontent.com/37978105/66697555-99ad2900-ed11-11e9-9059-ae7845e29584.png)

- 다중 프로그래밍의 특징

  - 높고 효율적인 프로세서 사용률(**효율적인 운영**) 증가
  - 많은 사용자의 프로그램이 거의 동시에 프로세서를 할당받는 듯한 느낌
  - 다중 프로그래밍 운영체제는 아주 복잡
  - 여러 작업을 준비 상태로 두려면 이를 메모리에 보관, 일정 형태의 메모리를 관리해야 함
  - 여러 작업이 수행할 준비를 갖추고 있으면, 이 중 하나를 선택하는 결정 방법 필요( 인터럽트 이용 수행하는 프로세서 스케줄링의 다중 프로그래밍으로, 현재 운영체제의 중심 주제)

  ![주석 2019-10-12 164920](https://user-images.githubusercontent.com/37978105/66697559-a3cf2780-ed11-11e9-8197-afd45ba59cbf.png)



### 시분할 시스템(TTS , Time Sharing System)

- 다중 프로그래밍을 논리적으로 확장한 개념, 프로세서가 다중 작업을 교대로 수행
- 다수의 사용자가 동시에 컴퓨터의 자원을 공유할 수 있는 기술
- CTSS(Compatible Time Sharing System) : MIT 에서 개발, 1961년 IBM 709에 탑재, 사용
- 1970년 초까지는 시분할 시스템 만들기가 아주 어렵고 비용도 많이 들어 일반화 못함
- 각 프로그램에 일정한 프로세서 사용 시간 또는 규정 시간량 할당, 컴퓨터와 대화하는 형식으로 실행
- 여러 사용자에게 짧은 간격으로 프로세서 번갈아 할당하여 마치 자기 혼자 프로세서를 독점하고 있는 양 착각하게 하여 여러 사용자가 단일 컴퓨터 시스템을 동시 사용 가능

![주석 2019-10-12 170732](https://user-images.githubusercontent.com/37978105/66697677-dc233580-ed12-11e9-969b-4f94aa23b95e.png)

- 시분할 시스템의 장점
  - 빠른 응답 제공
  - 소프트웨어의 중복 회피 가능
  - 프로세서 유휴시간 감소
- 시분할 시스템의 단점
  - 신뢰성 문제
  - 보안 의문 및 사용자 프로그램과 데이터의 무결성
  - 데이터 통신의 문제



- 다중 프로그래밍 시스템과 시분할 시스템 특징
  - 메모리에 여러 프로그램을 적재하므로 메모리 관리 필요
  - 어떤 프로그램을 먼저 실행할지 결정하는 스케줄링 개념 필요
  - 다중 프로그래밍 시스템의 목표 : 프로세서 사용 최대화
  - 시분할 시스템의 목표 : 응답시간 최소화



### 다중 처리(multiprocessing) 시스템

- 단일 컴퓨터 시스템 내에서 둘 이상의 프로세서 사용, 동시에 둘 이상의 프로세스 지원
- 여러 프로세서와 시스템 버스, 클록, 메모리와 주변장치 등 공유
- 빠르고, 프로세서 하나가 고장 나도 다른 프로세서 사용하여 작업 계속, 신뢰성 높음
- 프로세서 간의 연결, 상호작용, 역할 분담 등을 고려해야함
- 다중 처리 시스템을 구성하는 방법에는 비대칭(주종)적 구성과 대칭적 구성이 있음

![주석 2019-10-12 171945](https://user-images.githubusercontent.com/37978105/66697902-95363f80-ed14-11e9-9ae4-3968602f45b1.png)



### 분산 처리 시스템 (distributed processing system)

- 시스템마다 독립적인 운영체제와 메모리로 운영, 필요 시 통신하는 시스템
- 사용자에게는 중앙집중식 시스템처럼 보이는데, 다수의 독립된 프로세서에서 실행
- 데이터를 여러 위치에서 처리•저장, 여러 사용자가 공유
- 하나의 프로그램을 여러 프로세서에서 동시에 실행

![주석 2019-10-12 172443](https://user-images.githubusercontent.com/37978105/66698028-8d2acf80-ed15-11e9-9c84-69502f800380.png)



### 부팅 또는 부트스트래핑

- 운영체제를 메인 메모리에 적재하는 과정
- 부트 로더는 부트스트랩 로더(bootstrap loder) 줄인 말로 하드디스크와 같은 보조기억장치 에 저장된 운영체제를 메인 메모리에 적재하는 ROM에 고정시킨 소규모 프로그램

![주석 2019-10-12 174108](https://user-images.githubusercontent.com/37978105/66698288-856c2a80-ed17-11e9-96e5-6bc6d6d739ae.png)





## 3장 01 프로세스의 개념과 상태 변화

![주석 2019-10-13 023734](https://user-images.githubusercontent.com/37978105/66705510-84acb600-ed62-11e9-9831-ba2831641c3c.png)

### 프로세스 제어 블록 (PCB, Process Control Block)

- 운영체제가 프로세스 제어 시 필요한 프로세스 상태 정보 저장
- 특정 프로세스 정보 저장하는 데이터 블록이나 레코드(작업 제어 블록TCB, Task Control Block)
- 프로세스가 생성되면 메모리에 프로세스 제어 블록 생성,프로세스가 실행 종료하면 해당 프로세스 제어 블록도 삭제



### 프로세스 생성

- 프로세스 생성시 필요한 세부 작업 순서
  1. 새로운 프로세스에 프로세스 식별자 할당
  2. 프로세스의 모든 구성 요소를 포함할 수 있는 주소 공간과 프로세스 제어 블록 공간 할당
  3. 프로세스 제어 블록 초기화(프로세스 상태, 프로그램 카운터 등 초기화, 자원 요청, 프로세스 제어 정보(우선순위) 등을 포함)
  4. 링크(해당 큐에 삽입)

- 프로세스가 새로운 프로세스 생성 시 두 가지 샐행 발생
  - 부모 프로세스와 자식 프로세스 동시 실행
  - 부모 프로세스는 자식 프로세스 모두 종료할 때까지 대기



### 프로세스 종료

- 프로세스가 마지막 명령 실행, 종료하여 운영체제에 프로세스의 삭제 요청
- 일괄 처리 환경 : 작업 종료 의미의 신호로 인터럽트 발생 또는 시스템 호출로 중단 명령
- 대화형 환경 : 사용자가 로그오프 하거나 터미널을 닫음 
- abort(작업 취소) 명령어로 프로세스 종료
- 부모 프로세스의 자식 프로세스 종료
  - 보통 부모 프로세스 종료하면 운영체제가 자식 프로세스도 종료(연속 종료)
  - 자식 프로세스가 할당된 자원을 초과하여 자원을 사용할 떄
  - 자식 프로세스에 할당한 작업이 더는 없을 떄
- exit 명령어 : 유닉스에서 프로세스 종료
- wait 명령어 : 부모 프로세스가 자식 프로세스의 종료 기다림.
- 프로세스 종료 이유
  - 정상 종료 : 프로세스가 운영체제의 서비스 호출
  - 시간 초과
  - 실패 : 파일 검색 실패, 입출력이 명시된 횟수 초과하여 실패할 때
  - 산술 오류, 보호 오류, 데이터 오류 등, 메모리 부족, 액세스 위반 등



### 프로세스 제거

- 프로세스 파괴
- 사용하던 자원 시스템에 돌려주고, 해당 프로세스는 시스템 리스트나 테이블에서 사라져 프로세스 제어 블록 회수
- 프로그램은 여전히 디스크에 저장
- 자식 프로세스는 부모 프로세스를 제거하면 자동 제거



###  프로세스의 중단

- 시스템의 유휴시간 문제를 프로세스 중단(일시정지) 상태를 이용 해결
- 운영체제는 새로운 프로세스를 생성하여 실행하거나 실행 중인 프로세스를 중단했다가 다시 실행 하여 사용 가능, 후자의 방법 이용하면 시스템 전체의 부하를 증가시키지 않고 프로세스에 서비스 제공
- 실행에서 대기가 아닌 중단 상태 추가하면 특정 이벤트의 발생을 기다리면서 대기 상태가 되어 해당 이벤트가 발생할 떄 즉시 실행 상태로 바꿀수 있는 이점
- 다중 프로그래밍에서 중단
  - 프로세스 입출력 요구 외에 다른 원인으로 프로세스가 실행을 중단한 상태(자원 부족(대기) 상태)
- 단일 처리 시스템 : 해당 프로세스 스스로 중단
- 다중 처리 시스템 : 다른 프로세서가 실행 중인 프로세스 중단
- 중단된 프로세스는 다른 프로세서가 재시작하기 전에는 실행 불가
- 장시간 중단 시 해당 프로세스에 할당된 자원 반환, 자원의 성질에 따라 반환 자원 결정
  - 메인 메모리 : 프로세서 중단 즉시 반환
  - 보조 메모리 : 중단 시간 예측할 수 없거나 너무 길 때 반환
- 중단한 프로세스는 중단한 지점부터 다시 시작

![주석 2019-10-13 031310](https://user-images.githubusercontent.com/37978105/66705887-6e552900-ed67-11e9-8216-cc5dba7477b5.png)



### Created State

- 작업(job)을 커널에 등록
- PCB 할당 및 프로세스 생성
- 커널 : 가용 메모리 공간 체크 및 프로세스 상태 전이(ready or suspended ready)

![주석 2019-10-13 031611](https://user-images.githubusercontent.com/37978105/66705913-d9066480-ed67-11e9-9ee5-dfb20a62f3b7.png)

### Ready State

- 프로세서 외에 다른 모든 자원을 할당 받은 상태
- 프로세서 할당 대기 상태
- 즉시 실행 가능 상태

![주석 2019-10-13 031723](https://user-images.githubusercontent.com/37978105/66705937-11a63e00-ed68-11e9-90f8-c519c1769c92.png)



### Running State

- 포로세서와 필요한 자원을 모두 할당 받은 상태
- preemption (running -> ready) : 프로세서 스케줄링
- block/sleep (running -> asleep state) : I/O 등 자원 할당 요청

![주석 2019-10-13 032103](https://user-images.githubusercontent.com/37978105/66705988-95602a80-ed68-11e9-8994-2f32066b1b23.png)



### Blocked/Asleep State

- 프로세서 외에 다른 자원을 기다리는 상태
- 자원 할당은 system call에 의해 이루어짐
- wake-up (asleep -> ready)

![주석 2019-10-13 032316](https://user-images.githubusercontent.com/37978105/66706008-d3f5e500-ed68-11e9-9873-4e864f5ec01e.png)

### Suspended State

- 메모리를 할당 받지 못한(빼앗긴) 상태
- memory image를 swap device(프로그램 정보 저장을 위한  특별한 파일 시스템)에 보관
- 커널 또는 사용자에 의해 발생
- swap-out(suspended), swap-in(resume)

![주석 2019-10-13 032538](https://user-images.githubusercontent.com/37978105/66706030-2931f680-ed69-11e9-8701-d3f3dbf5d65e.png)



### Terminated/Zombie State

- 프로세스 수행이 끝난 상태
- 모든 자원 반납 후 커널 내부에 일부 PCB 정보만 남아 있는 상태
- (프로세스 관리를 위해 정보 수집 차원)

![주석 2019-10-13 032654](https://user-images.githubusercontent.com/37978105/66706052-57afd180-ed69-11e9-8dd9-4dbc287dc76d.png)

## 3장 03 스레드의 개념과 상태 변화

### 스레드(thread)의 개념

- 프로세스의 특성인 자원과 제어에서 **제어만 분리한 실행 단위**
- 프로세스 하나는 스레드 한 개 이상으로 나눌 수 있음
- 프로세스의 직접 실행 정보를 제외한 나머지 프로세스 관리 정보 공유
- 다른 프로시저 호출, 다른 실행 기록(별도 스택 필요)
- 관련 자원과 함께 메모리 공유 가능하므로 손상된 데이터나 스레드의 이상 동작 고려
- 경량 프로세스(LWP, Light Weight Process) : 프로세스의 속성 중 일부가 들어 있는 것
- 중량 프로세스(HWP, Heavy Weight Process) : 스레드 하나에 프로세스 하나인 전통적인 경우
- 같은 프로세스의 스레드들은 동일한 주소 공간 공유

![주석 2019-10-13 033205](https://user-images.githubusercontent.com/37978105/66706126-21268680-ed6a-11e9-9edd-ec8f4059e2c4.png)



![주석 2019-10-13 033230](https://user-images.githubusercontent.com/37978105/66706130-2552a400-ed6a-11e9-875c-eb8d76d27852.png)



- 스레드 병렬 수행
  - 프로세스 하나에 스레드들은 공동의 목적 달성을 위해 병렬 수행
  - 프로세스가 하나인 서로 다른 프로세서에서 프로그램의 다른 부분 동시 실행
- 스레드 병렬 수행의 이점
  - 사용자 응답성 증가
  - 프로세스의 자원과 메모리 공유 가능
  - 경제성 좋음
  - 다중 처리(멀티 프로세싱)로 성능과 효율 향상



## 4장 03 선형 그래프와 병행 프로그램

### 선행 그래프(precedence graph)

- **선행 제약의 논리적 표현**
- 프로세스 : 프로세스 집합과 이것의 선행 제약 두가지 요소로 정의
- **선행 제약** : 프로세스를 순서대로 다른 상태로 옮기는 것
  - 두 프로세스에 선행 제약이 없으면 이 둘은 독립적이므로 병행 실행 가능
- 순차적 활동을 표현하는 방향성 비순환 그래프
- 선행 그래프에서 노드는 소프트웨어 작업이거나 동시에 실행할 수 있는 프로그램 명령

![주석 2019-10-13 034108](https://user-images.githubusercontent.com/37978105/66706263-57b0d100-ed6b-11e9-8edf-d264a9f91e3b.png)



![주석 2019-10-13 034151](https://user-images.githubusercontent.com/37978105/66706269-6c8d6480-ed6b-11e9-97bc-89a47787ec94.png)



### fork와 join 구조

- 선행 그래프는 연산의 선행 제약 정의에 유용하지만, 2차원이라 프로그램에는 사용 곤란
- 선행 관계 명시 위해 **fork와 join 구조**, 병행 문장 (parbegin/parend) 등 다른 방법 필요

![주석 2019-10-13 034431](https://user-images.githubusercontent.com/37978105/66706295-cb52de00-ed6b-11e9-9a6f-9d389de2f90e.png)



![주석 2019-10-13 034525](https://user-images.githubusercontent.com/37978105/66706331-0d7c1f80-ed6c-11e9-9b6f-13ce5a4765a3.png)



![주석 2019-10-13 034543](https://user-images.githubusercontent.com/37978105/66706337-1cfb6880-ed6c-11e9-87cf-4380125368cc.png)

![주석 2019-10-13 034731](C:\Users\서동훈\Desktop\주석 2019-10-13 034731.png)

### 상호배제의 개념

- 병행프로세스에서 프로세스 하나가 공유 자원 사용 시 다른 프로세스들이 동일한 일을 할 수 없도록 하는 방법
- 읽기 연산은 공유 데이터에 동시에 접근해도 문제 발생 않음.
- 동기화 : 변수나 파일은 프로세스 별로 하나씩 차례로 읽거나 쓰도록 해야 하는데, 공유 자원을 동시에 사용하지 못하게 실행을 제어하는 방법 뜻 함.
  - 동기화는 순차적으로 재사용 가능한 자원을 공유하려고 상호작용하는 프로세스 사이에서 나타남
  - 동기화로 상호배제 보장할 수 있지만, 이 과정에서 교착 상태와 기아 상태가 발생할 수 있음

![주석 2019-10-13 134818](https://user-images.githubusercontent.com/37978105/66711094-28787f00-edc0-11e9-94cb-9e300ec35b7f.png)

- 상호배제의 조건
  1. 두 프로세스는 동시에 공유 자원에 진입 불가.
  2. 프로세스의 속도나 프로세서 수에 영향 받지 않음.
  3. 공유 자원을 사용하는 프로세스만 다른 프로세스 차단 가능
  4. 프로세스가 공유 자원을 사용하려고 너무 오래 기다려서는 안 됨



### 임계 영역의 개념

- 임계영역(CS, Critical Section) 
  - 임계 자원에 접근하고 실행하는 프로그램 코드 부분

- 다수의 프로세스 접근 가능하지만, 어느 한 순간에는 프로세스 하나만 사용 가능

![주석 2019-10-13 135140](https://user-images.githubusercontent.com/37978105/66711115-9cb32280-edc0-11e9-959a-e260a5ee1da8.png)

### 임계 영역 이용한 상호배제

- 간편하게 상호배제 구현이 가능하며, 어떤 프로세스가 진입이 가능한지 확인하려고 검사 하는 동작과 다른 프로세스 사용 금지하는 동작으로 분류

![주석 2019-10-13 135633](https://user-images.githubusercontent.com/37978105/66711148-4abecc80-edc1-11e9-80ff-90cd3d890498.png)



### 병행 프로세스에서 영역 구분

![주석 2019-10-13 135735](https://user-images.githubusercontent.com/37978105/66711396-d3d80280-edc5-11e9-8a29-f9ee7f5ed690.png)

### 임계 영역의 조건

1. 상호배제 : 어떤 프로세스가 임계 영역에서 작업 중, 다른 프로세스 임계 영역 진입 불가
2. 진행 : 임계 영역에 프로세스가 없는 상태에서 어떤 프로세스가 들어갈지 결정
3. 한정 대기 : 다른 프로세스가 임계 영역을 무한정 기다리는 상황 방지 위해 임계 영역에 한 번 들어갔던 프로세스는 다음에 임계 영역에 다시 들어갈 때 제한



### 상호배제 방법

![주석 2019-10-13 150054](https://user-images.githubusercontent.com/37978105/66711621-4ba82c00-edca-11e9-9211-fbd38f949ec1.png)





### 데커의 알고리즘

- 데커의 알고리즘 개념
  - 두 프로세스가 서로 통신하려고 공유 메모리를 사용하여 충돌 없이 단일 자원을 공유할 수 있도록 허용하는 것
  - 다익스트라 임계 영역 문제에 적용
  - 병행 프로그래밍 상호배제 문제의 첫 번째 해결책
  - 각 프로세스 플래그 설정 가능, 다른 프로세스 확인 후 플래그 재설정 가능
  - 프로세스가 임계 영역에 진입하고 싶으면 플래그 설정하고 대기

- Mutex 연산 조건
  - Mutual Exclusion(상호배제) : CS에 Process가 존재하면 다른 Process 진입금지
  - Progress(진행) : CS가 비어 있는 경우, 다른 process가 진입하는 것을 방해 X
  - Bounded waiting(한정대기) : Process의 CS 진입은 유한시간 내에 허용



### Two Process Mutex

![주석 2019-10-13 152729](https://user-images.githubusercontent.com/37978105/66711808-0980e980-edce-11e9-8e6f-e7f4ba163e4d.png)

- Mutex 조건 위배사항 ( 진행 위반 )
  1. P0가 repeat에서 종료되면 P1은 CS에 진입할 수 없다.
  2. 한 Process 가 연속 CS 진입 불가



![주석 2019-10-13 153040](https://user-images.githubusercontent.com/37978105/66711825-6ed4da80-edce-11e9-87a2-7076fdf3df79.png)

- Mutex 조건 위배사항 ( 상호배제 위반 )
  1. P0가 CS 진입 전 Preemption(인터럽트), P1이 CS에 진입
  2. 이후 P0가 CS에 진입 -> P0와 P1이 동시에 CS에 진입



![주석 2019-10-13 153232](https://user-images.githubusercontent.com/37978105/66711852-b52a3980-edce-11e9-8688-5fd1c3419742.png)

- Mutex 조건 위배사항 ( 진행, 한정대기 위반 )
  1. P0가 flag[0] <- true; 의사를 반영 후 Preemption
  2. P1이 flag[1] <- true; 의사를 반영 후 preemption
  3. CS는 empty and P0, P1 무한대기



### Dekker's Algorithm

![주석 2019-10-13 154506](https://user-images.githubusercontent.com/37978105/66711961-8a40e500-edd0-11e9-87ec-a0ff43701640.png)



![주석 2019-10-13 154522](https://user-images.githubusercontent.com/37978105/66711963-8f9e2f80-edd0-11e9-96ec-57592d360977.png)

​	

![주석 2019-10-13 154124](https://user-images.githubusercontent.com/37978105/66711932-038c0800-edd0-11e9-82e7-2882e6f5a96d.png)

![주석 2019-10-13 154142](https://user-images.githubusercontent.com/37978105/66711933-071f8f00-edd0-11e9-8d74-7ee6279f0fd0.png)

- 데커의 알고리즘 특징
  - 특별한 하드웨어 명령문 필요 없음
  - 임계 영역 바깥에서 수행 중인 프로세스가 다른 프로세스들이 임계 영역 진입 막지 않음
  - 임계 영역에 들어가기를 원하는 프로세서 무한정 기다리게 하지 않음



### 테스 세마포 모니터는 객관식으로만 출제



###  테스(TAS, TestAndSet) 명령어

- TAS 명령어의 개념
  - 공유 변수 수정하는 동안 인터럽트 방생 억제하여 임계 영역 문제 간단 해결
  - 항상 적용할 수 없고 실행 효율 현저히 떨어짐
  - 소프트웨어적인 해결책은 더 복잡하고 프로세스가 2개 이상일 때는 더 많은 대기 가능성
  - 알고리즘이 간단, 하나의 메모리 사이클에서 수행하여 경쟁 상황 해결
  - 기계명령어 2개(원자적연산 명령어 TAS, TAS에 지역변수 lock 설정명령어)
  - 일부 시스템에서 원자 명령어의 하나로,읽기와 쓰기 모두 제공
  - 해당 주소의 값을 읽고 새 값으로 교체하면서 해당 메모리 위치의 이전 값 반환

### TAS Algorithm

![주석 2019-10-13 155241](https://user-images.githubusercontent.com/37978105/66712032-b315aa00-edd1-11e9-9494-086ddd6e8807.png)



![주석 2019-10-13 155254](https://user-images.githubusercontent.com/37978105/66712059-05ef6180-edd2-11e9-8ac3-04b6da218791.png)

![주석 2019-10-13 155307](https://user-images.githubusercontent.com/37978105/66712065-14d61400-edd2-11e9-8fb7-82c038247ae7.png)

- TAS 연산 조건 위배사항 ( 3개 이상의 프로세스의 경우 한정대기 위반 )
  1. P1이 CS 진입
  2. target에 P2, P3 .... 가 누가 먼저 CS에 진입하는가?



![주석 2019-10-13 155818](https://user-images.githubusercontent.com/37978105/66712082-4f3fb100-edd2-11e9-83f0-8d9674b71331.png)

- TAS 장점과 단점
  - 장점
    - 사용자 수준에서 가능하다
      - 메인 메모리를 공유하는 다중 프로세서나 단일 프로세서에서 프로세스 수에 관계없이 적용할 수 있다.
      - lock 변수 수에 상관없이 구현할 수 있다.
      - 구현이 단순하고 확인이 용이한다.
      - 다중 임계 영역을 지원한다
  - 단점
    - 바쁜 대기 발생
      - 프로세서 시간 소모가 크다
      - 대기 프로세스는 비생산적, 자원이 소모되는 대기 루프에 남는다.
    - 기아 상태 발생 : 프로세스가 임계 영역을 떠날 때 프로세스 하나 이상을 대기하는 경우 가능하다
    - 교착 상태 발생 : 플래그는 우선순위가 낮은 프로세스가 재설정 할 수 있지만, 우선순위가 높은 프로세스가 선점한다. 따라서 우선순위가 낮은 프로세스는 lock을 가지고, 우선순위가 높은 프로세스가 이것을 얻으려고 시도할 때 높은 우선순위 프로세스는 무한정 바쁜 대기가 될 것이다.
